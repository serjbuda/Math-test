{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee472d1f-c3d0-4a21-840d-430e0eff3df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train original shape (60000, 28, 28)\n",
      "y_train original shape (60000,)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 800)               628000    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 800)               3200      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                8010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 639210 (2.44 MB)\n",
      "Trainable params: 637610 (2.43 MB)\n",
      "Non-trainable params: 1600 (6.25 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "107/107 [==============================] - 14s 96ms/step - loss: 0.9478 - sparse_categorical_accuracy: 0.6850 - val_loss: 1.0517 - val_sparse_categorical_accuracy: 0.7663\n",
      "Epoch 2/50\n",
      "107/107 [==============================] - 10s 93ms/step - loss: 0.6468 - sparse_categorical_accuracy: 0.7799 - val_loss: 0.6979 - val_sparse_categorical_accuracy: 0.8132\n",
      "Epoch 3/50\n",
      "107/107 [==============================] - 10s 97ms/step - loss: 0.5781 - sparse_categorical_accuracy: 0.8003 - val_loss: 0.5372 - val_sparse_categorical_accuracy: 0.8267\n",
      "Epoch 4/50\n",
      "107/107 [==============================] - 10s 95ms/step - loss: 0.5422 - sparse_categorical_accuracy: 0.8127 - val_loss: 0.4632 - val_sparse_categorical_accuracy: 0.8405\n",
      "Epoch 5/50\n",
      "107/107 [==============================] - 10s 97ms/step - loss: 0.5162 - sparse_categorical_accuracy: 0.8188 - val_loss: 0.4332 - val_sparse_categorical_accuracy: 0.8454\n",
      "Epoch 6/50\n",
      "107/107 [==============================] - 10s 92ms/step - loss: 0.4920 - sparse_categorical_accuracy: 0.8283 - val_loss: 0.4159 - val_sparse_categorical_accuracy: 0.8522\n",
      "Epoch 7/50\n",
      "107/107 [==============================] - 10s 92ms/step - loss: 0.4770 - sparse_categorical_accuracy: 0.8339 - val_loss: 0.4065 - val_sparse_categorical_accuracy: 0.8538\n",
      "Epoch 8/50\n",
      "107/107 [==============================] - 10s 94ms/step - loss: 0.4606 - sparse_categorical_accuracy: 0.8387 - val_loss: 0.3999 - val_sparse_categorical_accuracy: 0.8565\n",
      "Epoch 9/50\n",
      "107/107 [==============================] - 13s 120ms/step - loss: 0.4487 - sparse_categorical_accuracy: 0.8427 - val_loss: 0.3942 - val_sparse_categorical_accuracy: 0.8573\n",
      "Epoch 10/50\n",
      "107/107 [==============================] - 12s 115ms/step - loss: 0.4356 - sparse_categorical_accuracy: 0.8460 - val_loss: 0.3889 - val_sparse_categorical_accuracy: 0.8607\n",
      "Epoch 11/50\n",
      "107/107 [==============================] - 10s 95ms/step - loss: 0.4280 - sparse_categorical_accuracy: 0.8487 - val_loss: 0.3831 - val_sparse_categorical_accuracy: 0.8623\n",
      "Epoch 12/50\n",
      "107/107 [==============================] - 10s 96ms/step - loss: 0.4185 - sparse_categorical_accuracy: 0.8504 - val_loss: 0.3794 - val_sparse_categorical_accuracy: 0.8648\n",
      "Epoch 13/50\n",
      "107/107 [==============================] - 10s 98ms/step - loss: 0.4115 - sparse_categorical_accuracy: 0.8540 - val_loss: 0.3752 - val_sparse_categorical_accuracy: 0.8655\n",
      "Epoch 14/50\n",
      "107/107 [==============================] - 10s 95ms/step - loss: 0.4027 - sparse_categorical_accuracy: 0.8574 - val_loss: 0.3725 - val_sparse_categorical_accuracy: 0.8656\n",
      "Epoch 15/50\n",
      "107/107 [==============================] - 10s 96ms/step - loss: 0.3973 - sparse_categorical_accuracy: 0.8591 - val_loss: 0.3702 - val_sparse_categorical_accuracy: 0.8686\n",
      "Epoch 16/50\n",
      "107/107 [==============================] - 10s 97ms/step - loss: 0.3910 - sparse_categorical_accuracy: 0.8610 - val_loss: 0.3676 - val_sparse_categorical_accuracy: 0.8675\n",
      "Epoch 17/50\n",
      "107/107 [==============================] - 11s 101ms/step - loss: 0.3886 - sparse_categorical_accuracy: 0.8616 - val_loss: 0.3638 - val_sparse_categorical_accuracy: 0.8692\n",
      "Epoch 18/50\n",
      "107/107 [==============================] - 11s 106ms/step - loss: 0.3830 - sparse_categorical_accuracy: 0.8638 - val_loss: 0.3623 - val_sparse_categorical_accuracy: 0.8692\n",
      "Epoch 19/50\n",
      "107/107 [==============================] - 11s 101ms/step - loss: 0.3750 - sparse_categorical_accuracy: 0.8668 - val_loss: 0.3595 - val_sparse_categorical_accuracy: 0.8715\n",
      "Epoch 20/50\n",
      " 24/107 [=====>........................] - ETA: 8s - loss: 0.3667 - sparse_categorical_accuracy: 0.8663"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Завантаження даних Fashion MNIST\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "print(\"x_train original shape\", x_train.shape)\n",
    "print(\"y_train original shape\", y_train.shape)\n",
    "\n",
    "classes = ['футболка', 'брюки', 'свитер', 'платье', 'пальто', 'туфли', 'рубашка', 'кроссовки', 'сумка', 'ботинки']\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(100, 150):\n",
    "    plt.subplot(5, 10, i - 100 + 1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(classes[y_train[i]])\n",
    "\n",
    "# Преобразовання розмірності зображень\n",
    "x_train = x_train.reshape(60000, 28, 28)\n",
    "x_test = x_test.reshape(10000, 28, 28)\n",
    "# Нормалізація даних\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "# Побудова моделі без Conv2D шару\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28, 28)))\n",
    "model.add(Dense(units=800, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(rate=0.5))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "# Компіляція моделі\n",
    "model.compile(optimizer=SGD(learning_rate=0.01),\n",
    "              loss=SparseCategoricalCrossentropy(),\n",
    "              metrics=[SparseCategoricalAccuracy()])\n",
    "\n",
    "# Посмотрим на архітектуру мережі\n",
    "model.summary()\n",
    "\n",
    "# Навчання моделі\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=450,\n",
    "                    epochs=50,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=1)\n",
    "\n",
    "# Збереження моделі\n",
    "model.save('fashion_mnist_dense.h5')\n",
    "\n",
    "# Оцінка якості навчання\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Доля верних ответов на тестовых данных, в процентах:\", round(scores[1] * 100, 2))\n",
    "\n",
    "# Распознавання одягу\n",
    "n_rec = 496\n",
    "plt.imshow(x_test[n_rec], cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "# Підготовка зображення для розпізнавання\n",
    "x = x_test[n_rec].reshape(1, 28, 28)  # Повернули форму вхідного зображення до (1, 28, 28)\n",
    "\n",
    "# Розпізнавання\n",
    "prediction = model.predict(x)\n",
    "\n",
    "predicted_class = tf.argmax(prediction, axis=1).numpy()[0]\n",
    "print(\"Номер класса:\", predicted_class)\n",
    "print(\"Название класса:\", classes[predicted_class])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dea6bf2-7b36-4242-ad70-6d68eb684b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
